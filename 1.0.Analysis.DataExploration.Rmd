

# Methods and Analysis
          section that explains the process and techniques used, including data cleaning, data exploration and visualization, insights gained, and your modeling approach

```{r initial, include = FALSE}
##########################################################
# Create edx set, validation set (final hold-out test set)
##########################################################

# Note: this process could take a couple of minutes

if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(data.table)) install.packages("data.table", repos = "http://cran.us.r-project.org")

library(tidyverse)
library(caret)
library(data.table)

# MovieLens 10M dataset:
# https://grouplens.org/datasets/movielens/10m/
# http://files.grouplens.org/datasets/movielens/ml-10m.zip

dl <- tempfile()
```



```{r initial1, include = FALSE}
library(dslabs)
library(tidyverse)
library(rafalib)
data("movielens")

edx <- movielens

```

# Loss function

The decision of better estimate will be based on the residual mean squared error (RMSE) on a test set. We define $y_{u,i}$ as the rating for movie $i$ by user $u$ and denote our prediction with $\hat{y}_{u,i}$. The RMSE is then defined as:

$$
\mbox{RMSE} = \sqrt{\frac{1}{N} \sum_{u,i}^{} \left( \hat{y}_{u,i} - y_{u,i} \right)^2 }
$$
with $N$ being the number of user/movie combinations and the sum occurring over all these combinations.


# Data exploration and visualization

## The dataset

The movielens 10M dataset has `r format(nrow(movielens),big.mark=",")` rows but this only  `r format(n_distinct(movielens$movieId),big.mark=",")` different movies and `r format(n_distinct(movielens$userId),big.mark=",")` users. But if we create a matrix of the movies that we have in the dataset and the users we get a matrix of `r  n_distinct(movielens$movieId) * n_distinct(movielens$userId)` elements with a rating witch represent only the `r  format(100 * nrow(movielens)/(n_distinct(movielens$movieId) * n_distinct(movielens$userId)), digits =2, nsmall =2)`% of the matrix. The rest is unknown: the user $u$ did not rate the movie $i$.
A matrix with mostly empty cells is called sparse, and the opposite to that (a mostly filled matrix) is called dense.

## Exploration
Each row in this dataset is and rating to the  movie i by the user u. But more info is stored and we will review initially if we can see some aspect we need to considered in the model.

Remeber, we hace this columns:
```{r , echo=FALSE}
names(movielens)
```
The features/variables/columns in dataset are:

| Name       | Type     | Description     |
| :--------- | :------: | :-------------- |
|**movieId**|`r class(edx$movieId)`|  contains the unique identification number for each movie.
|**title**|`r class(edx$title)`|  contains the title of each movie.
|**year**| `r class(edx$year)`| contains the year of the movie release.
|**genres**|`r class(edx$genres)`| contains a list of pipe-separated of genre of each movie.
|**userId**|`r class(edx$userId)`| contains the unique identification number for each user.
|**rating**|`r class(edx$rating)`| contains the rating of one movie by one user. Ratings are made on a 5-Star scale with half-star increments.
|**timestamp**|`r class(edx$timestamp)`| contains the timestamp for one specific rating provided by one user.




### MovieId

The movieId as its name make reference it s the Id of the movies in this dataset. Could be the title of the movie be enough? If that it is true, the number must be equal (a necessary condition is not a sufficient condition):

```{r, echo=FALSE}
n_distinct(edx$movieId)
n_distinct(edx$title)

```
They are not. This is becuse some movies has the same name but not the same movieId...Why? Because they are released in different year!

```{r, echo=FALSE}

edx %>% group_by(movieId,title,year) %>% summarize(n()) %>% 
  group_by(title)%>%summarize(n = n(), year = year) %>% filter( n != 1)

```

Then we use the movieID for the analysis and the title it is not, except to show the results to make sense to ourself.

One aspect to consider is that not all the movies has the same numbers of rating, e. gr., some movies has more vote than the others as we can see in the following histograms:

```{r histograms_M10, echo=FALSE}
movielens %>% 
  dplyr::count(movieId) %>% 
  ggplot(aes(n)) + 
  geom_histogram(bins = 30, color = "black") + 
  scale_x_log10() + 
  ggtitle("Movies rated") +
  xlab("Number of rate per movie (log scale)")
```
And obviously, not all the movies are rated equally:

```{r, echo=FALSE}
movielens %>% 
  group_by(movieId) %>% 
  summarise(avg_by_movieId = mean(rating), n = n()) %>%
  ggplot(aes(avg_by_movieId)) + 
  geom_histogram(bins = 10, color = "black") + 
  #scale_x_log10() + 
  ggtitle("Movies rating") +
  xlab("Rating")
```
### rating

The rating is the value we want to predict but it is present in our dataset.

```{r,echo=FALSE}
unique(edx$rating) %>% data.frame() %>% arrange_all() %>% t() %>% as.numeric()
```
### userId

This is the user who rate or vote. Not the users rate the same amount of movies as we can see in the following histograms:

```{r , echo=FALSE}
movielens %>%
  dplyr::count(userId) %>% 
  ggplot(aes(n)) + 
  geom_histogram(bins = 30, color = "black") + 
  scale_x_log10() +
  ggtitle("Users who rate") +
  xlab("Number of users who rate movies (log scale)")
```


```{r}

movielens %>%
  group_by(userId) %>% 
  summarise(avg_by_userId = mean(rating), n = n()) %>%
  ggplot(aes(avg_by_userId)) + 
  geom_histogram(bins = 20, color = "black") + 
  ggtitle("Rating by the users") +
  xlab("rating")
```

#year
The yaer of the release of the movie can be affected in the rating? Too old movies can be under estemimeted under the new ones?


```{r , echo=FALSE}
movielens %>%
  dplyr::count(year) %>% 
  ggplot(aes(x=year,y=n)) + 
  geom_line() + 
  #scale_x_log10() +
  ggtitle("Movie rated by Year of the release") +
  xlab("Year of the release of the movie") +
  ylab("count")
```
Is the rating independent of the year of the movie?

```{r}
movielens %>%
  group_by(year) %>% 
  summarise(avg_by_year = mean(rating), n = n()) %>%
  ggplot(aes(avg_by_year)) + 
  geom_histogram(bins = 30, color = "black") + 
  ggtitle("Rateing by Year of the movie") +
  xlab("Rating")
```
### timestamp

Is the rating process affected by the time? timestamp can help us to find any relationship. First the histogram of the rating:

```{r , echo=FALSE}
movielens %>%
  mutate(date = as.Date(as.POSIXct(timestamp, origin = "1970-01-01"))) %>%
  dplyr::count(date) %>% 
  ggplot(aes(n)) + 
  geom_histogram(bins = 30, color = "black") + 
  scale_x_log10() +
  ggtitle("Timestamp of the rate") +
  xlab("Timestamp of rate movies (log scale)")


```

The rating procees it is constant over time:

```{r}
movielens %>%
  dplyr::count(timestamp) %>% 
  ggplot(aes(as.Date(as.POSIXct(timestamp, origin = "1970-01-01")))) + 
  geom_histogram(bins = 30) + 
  ggtitle("Timestamp of the rated movie") +
  xlab("Year") +
  ylab("count")
```
But all year the user are rating equal? This histogram shows they do not.

```{r}
movielens %>%
  group_by(timestamp) %>% 
  summarise(avg_by_tm = mean(rating), n = n()) %>%
  ggplot(aes(avg_by_tm)) + 
  geom_histogram(bins = 10, color = "black") + 
  ggtitle("Rateing by Year of the movie") +
  xlab("Rating")
```

### genres

The genres in an arbitrary attribute that a move has. Actually can have more than one gender that in this dataset is separated in this column by |.


```{r}
n_distinct(edx$genres)
```
Then we have a lot of genres!


```{r}
movielens %>% group_by(genres) %>%
  summarise(n = n(), rat_gen = mean(rating)) %>%
  ggplot(aes(rat_gen)) + 
  geom_histogram(bins = 30, color = "black") + 
  ggtitle("Gender of the movie") +
  xlab("rating")
```

```{r}
head(edx) %>%
    select(title, genres)
```



We can create a new dataset that separate this genres, making the dataset bigger and taking care of 2 aspects:
1.- If we do in the training set we hve to do it in the validation set
2.- **Only** use for genres analysis, because we are going to change the dataset and any other analysis will be mislead

```{r}

edx_genres <- edx %>% filter(genres != "(no genres listed)") %>% separate_rows(genres)
head(edx_genres)
```


```{r}
n_distinct(edx_genres$genres)
unique(edx_genres$genres)
```

Now can we see by genres thare are differences:

```{r}
edx_genres %>% group_by(genres) %>%
  summarise(n = n(), rat_gen = mean(rating)) %>%
  ggplot(aes(rat_gen)) + 
  geom_histogram(bins = 30, color = "black") + 
  ggtitle("Gender of the movie") +
  xlab("rating")
```
And we can see that different genres has different average rating:
```{r, echo=FALSE}
edx_genres %>% group_by(genres) %>%
  summarise(n = n(), rat_gen = mean(rating)) %>%
  ggplot(aes(x= genres, y=rat_gen)) + 
  geom_point() + 
  ggtitle("Rating by the Gender") +
  xlab("Genres") +
  ylab("rating") +
  theme(axis.text.x = element_text(angle = 60))   # Rotate axis labels
```



We start now making the first model. But remember, not with the whole movilen 10M dataset, only with the training.


How is it the rating affected by this predictors?


# Cleaning


# Models

## Fisrt Model...just the average movie rating

The most basic and quick approach it is consider that a rating for a movie is just the average of all rating, e. gr., assumes the same rating for all movies and all users


$$
 y_{u,i} = \mu + \varepsilon_{i,u}
$$
with $\varepsilon_{i,u}$ independent errors sampled from the same distribution centered at 0 and $\mu$ the "true" rating for all movies......

Let's calculate the average and see what RMSE we get:

```{r Fisrt Model}
mu_hat <- mean(edx$rating)
mu_hat
mu_hat_rmse <- RMSE(edx$rating, mu_hat)
mu_hat_rmse
```
Let's see how this distrubation of rating is and we add the means just calculated and one RMSE up and down from this means:

```{r}
edx %>% group_by(rating) %>% ggplot(aes(rating)) + geom_histogram(bins = 10) + geom_vline(xintercept=mu_hat) +
  geom_vline(xintercept= c(mu_hat-mu_hat_rmse,mu_hat+mu_hat_rmse), linetype='dashed', color='blue', size=0.5) +
  ggtitle("Distribution of Rating")
```

We can appreciate than the RMSE of `r mu_hat_rmse` it is high in the range of the rating> beside that we can see the distribution it is not quite similar to a Gaussian distribution and the full number rating (1,2,3,4 and 5) are more common than fractional rating (0.5, 1.5, 2.5, 3.5 and 4.5). The work now it is improve this initial RSME

## Cleaning

One aspect in the machine learning is to check the data and see id it is leading us to a wrong conclusion. We start with de best and worst movie according to the rating:

```{r}
movie_rate <- edx %>% 
  group_by(movieId) %>% 
  mutate(avg_rating = mean(rating), n = n()) %>%
  select(-rating, -userId, -timestamp, -genres ) %>%
  distinct()


movie_rate %>% arrange(desc(avg_rating))

```
The best movies we do not see the ones we expected. Is this an error in our knowledge of movies? Take a look to the column n, which n stand por the number of rated received: it is a value to low 1 or 2 rated. Let see what is happening with the worse:

```{r}
movie_rate %>% arrange(avg_rating)
```
and we see before in the Movie Distribution that there are a lot of movies with 1 or 2 rating. How many? Can be dropped?

```{r}
nrow(filter(movie_rate, n <= 2))/nrow(movie_rate)

```
It is a big group of data. It can not be dropped and it has same information anyway. Can we used? Yes!

### Centering the movie rating

```{r}
edx1 <- edx %>% mutate(centered.rating = scale(rating, scale = FALSE))

```

Now the rating just moved the mu_hat, and the new average in zero. Why? Because when we calculate the average by movie, we do not want to change the average but give more representation to the ones which has more rating and the one with fewer move to the means. The logic behaind is that the probability of the next rate will be the average (in the assuntion of independent event, amongs others)

```{r}
lambda <- 3
movie_rate_lambda <- edx1 %>% 
  group_by(movieId) %>% 
  mutate(lamda_rating = sum(centered.rating)/(n()+lambda), n = n()) %>%
  select(-rating, -userId, -timestamp, -genres, -centered.rating ) %>%
  distinct()

edx2 <- edx1 %>% 
  group_by(movieId) %>% 
  mutate(lamda_rating = sum(centered.rating)/(n()+lambda), n = n())# %>%
  #select(-rating, -timestamp, -genres, -centered.rating ) %>%
  #distinct()
```

Now checks the top movies:
```{r}
movie_rate_lambda %>% arrange(desc(lamda_rating))



```
Now they are better known and have a significative numbers of rating.


### Movie effect

Some movies are over the average and other under it. Can be see that in the data? Is there some preference for some movies over others? This is the code assuming that there is one effect for the movie itseft (one item has better preference than other)

$$
 y_{u,i} = \mu + b_{i} + \varepsilon_{i,u}
$$

with $\varepsilon_{i,u}$ independent errors sampled from the same distribution centered at 0 and $\mu$ the "true" rating for all movies and $b_{i}$ the average rating for movie i or the "movie effect".

```{r}
movie_effect_avgs <- movie_rate_lambda %>% 
  group_by(movieId) %>% 
  mutate(b_i = mean(lamda_rating)) %>%
  #select(-rating, -userId, -timestamp, -genres, -centered.rating ) %>%
  distinct()

edx3 <- edx2 %>% 
  group_by(movieId) %>% 
  mutate(b_i = mean(lamda_rating)) %>%
  #select(-rating, -userId, -timestamp, -genres, -centered.rating ) %>%
  distinct()

movie_effect_avgs
```


Let see how this movie effect is distributed:
```{r}
b_i_avg <- mean(movie_effect_avgs$b_i)
movie_effect_avgs %>%
 ggplot(aes(b_i)) + 
  geom_histogram(bins = 10, color = "black") + 
  ggtitle("Movie effect") +
  geom_vline(xintercept = b_i_avg, linetype='dashed', color='blue', size=0.5) +
  xlab("b_i")
```

Now compute the RMSE

```{r}
predicted_ratings <- mu_hat + edx1 %>% 
     left_join(movie_effect_avgs, by='movieId') %>%
     .$b_i

model_1_rmse <- RMSE(edx$rating, predicted_ratings)
mean(model_1_rmse)
```
### User effect

We just considered the movie. What is about the user? All the user rate equal the same movie...certanlly not.

The we can have a new model:

$$
 y_{u,i} = \mu + b_{i} + b_{u} + \varepsilon_{i,u}
$$

 $\mu$ the "true" rating for all movies and $b_{i}$ the average rating for movie i or the "movie effect" and $b_{u}$ the average rating for user u or "user effect" and $\varepsilon_{i,u}$ independent errors sampled from the same distribution centered at 0

Let's calcuate this $b_{u}$:

```{r}
user_avgs <- edx1 %>% 
  left_join(movie_effect_avgs, by='movieId') %>%
  group_by(userId) %>%
  summarize(b_u = mean(lamda_rating - b_i))

edx4 <- edx3 %>% 
  #left_join(movie_effect_avgs, by='movieId') %>%
  group_by(userId) %>%
  mutate(b_u = mean(rating - mu_hat - b_i)) #%>%
  #distinct()



b_u_avg <- mean(user_avgs$b_u)
```


```{r}
edx2 %>% 
  group_by(userId) %>% 
  summarize(b_u = mean(lamda_rating )) %>% 
  filter(n()>=100) %>%
  ggplot(aes(b_u)) + 
  geom_histogram(bins = 30, color = "black") +
  ggtitle("User effect") +
  geom_vline(xintercept = b_u_avg, linetype='dashed', color='blue', size=0.5) +
  xlab("b_u")

# init
edx4 %>% 
  group_by(userId) %>% 
  summarize(b_u = mean(rating - mu_hat - b_i)) %>% 
  filter(n()>=100) %>%
  ggplot(aes(b_u)) + 
  geom_histogram(bins = 30, color = "black")
```
The RMSE


```{r}

predicted_ratings <-  edx4 %>% 
  #left_join(movie_effect_avgs, by='movieId') %>%
  #left_join(user_avgs, by='userId') %>%
  mutate(pred = mu_hat + b_i + b_u) %>%
  .$pred

model_2_rmse <- RMSE(edx$rating, predicted_ratings)
mean(model_2_rmse)
```
see movie_effect_avgs & movie_avgs....

with scale we take out user effect.....
