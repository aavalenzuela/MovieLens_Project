

# Methods and Analysis
          In this section we explain the process and techniques used, including data cleaning, data exploration and visualization, insights gained, and your modeling approach.





```{r initial1, include = FALSE}
#delete in final doc
library(dslabs)
library(tidyverse)
library(rafalib)
data("movielens")

edx <- movielens

```

# Loss function

The decision of better estimate will be based on the residual mean squared error (RMSE) on a test set. We define $y_{u,i}$ as the rating for movie $i$ by user $u$ and denote our prediction with $\hat{y}_{u,i}$. The RMSE is then defined as:

$$
\mbox{RMSE} = \sqrt{\frac{1}{N} \sum_{u,i}^{} \left( \hat{y}_{u,i} - y_{u,i} \right)^2 }
$$
with $N$ being the number of user/movie combinations and the sum occurring over all these combinations.


# Data exploration and visualization

## The dataset

The movielens 10M dataset had been split in edx and validation (90% and 10% respectively). Because we do not know nothing about validation (only we deduced from edx) we can see that edx has `r format(nrow(edx),big.mark=",")` rows but this only  `r format(n_distinct(edx$movieId),big.mark=",")` different movies and `r format(n_distinct(edx$userId),big.mark=",")` users. But if we create a matrix of the movies that we have in the dataset and the users we get a matrix of `r  n_distinct(edx$movieId) * n_distinct(edx$userId)` elements with a rating witch represent only the `r  format(100 * nrow(edx)/(n_distinct(edx$movieId) * n_distinct(edx$userId)), digits =2, nsmall =2)`% of the matrix. The rest is unknown: the user $u$ did not rate the movie $i$.
A matrix with mostly empty cells is called sparse, and the opposite to that (a mostly filled matrix) is called dense.

## Exploration
Each row in this dataset is and rating to the  movie i by the user u. But more info is stored and we will review initially if we can see some aspect we need to considered in the model.

Remeber, we have these columns:
```{r, echo=FALSE}
names(edx)
```
The features/variables/columns in dataset are:

| Name       | Type     | Description     |
| :--------- | :------: | :-------------- |
|**movieId**|`r class(edx$movieId)`|  contains the unique identification number for each movie.
|**title**|`r class(edx$title)`|  contains the title of each movie and the year of release.
|**genres**|`r class(edx$genres)`| contains a list of pipe-separated of genre of each movie.
|**userId**|`r class(edx$userId)`| contains the unique identification number for each user.
|**rating**|`r class(edx$rating)`| contains the rating of one movie by one user. Ratings are made on a 5-Star scale with half-star increments.
|**timestamp**|`r class(edx$timestamp)`| contains the timestamp for one specific rating provided by one user.




### MovieId

The movieId as its name make reference it s the Id of the movies in this dataset. Could be the title of the movie be enough? If that it is true, the number must be equal (a necessary condition is not a sufficient condition):

```{r, echo=FALSE}
n_distinct(edx$movieId)
n_distinct(edx$title)

```
They are not. This is because some movies has the same title but not the same movieId...Why? 

```{r, echo=FALSE, message=FALSE}

edx %>% group_by(movieId,title) %>% summarize(n()) %>% 
  group_by(title)%>%summarize(n = n(), movieId = movieId) %>% filter( n != 1)

```

Then we use the movieID for the analysis and the title it is not, except to show the results to make sense to our self.

One aspect to consider is that not all the movies has the same numbers of rating, e. gr., some movies has more vote than the others as we can see in the following histograms:

```{r histograms_M10, echo=FALSE}
edx %>% 
  dplyr::count(movieId) %>% 
  ggplot(aes(n)) + 
  geom_histogram(bins = 30, color = "black") + 
  scale_x_log10() + 
  ggtitle("Movies rated") +
  xlab("Number of rate per movie (log scale)")
```
You can see some movies has over a hundred of rating but one hundred of rating it is quite usual.

And obviously, not all the movies are rated equally:

```{r, echo=FALSE}
edx %>% 
  group_by(movieId) %>% 
  summarise(avg_by_movieId = mean(rating), n = n()) %>%
  ggplot(aes(avg_by_movieId)) + 
  geom_histogram(bins = 10, color = "black") + 
  #scale_x_log10() + 
  ggtitle("Movies rating") +
  xlab("Rating")
```
and here where our prediction system enter in play.


### rating

The rating is the value we want to predict but it is present in our dataset. This one allow us to training our system and it is called supervised learning algorithms in the AI.

```{r,echo=FALSE}
unique(edx$rating) %>% data.frame() %>% arrange_all() %>% t() %>% as.numeric()
```

As we mention, the output it is a discrete, only 10 possible values.


### userId

This is the user who rate or vote. Not all the users rate the same amount of movies as we can see in the following histograms:

```{r, echo=FALSE}
edx %>%
  dplyr::count(userId) %>% 
  ggplot(aes(n)) + 
  geom_histogram(bins = 30, color = "black") + 
  scale_x_log10() +
  ggtitle("Users who rate") +
  xlab("Number of users who rate movies (log scale)")
```
Yo can see that are user that rate over a one thousand of movies!

Again, not all the user rate the movies in the same way.

```{r, echo=FALSE}

edx %>%
  group_by(userId) %>% 
  summarise(avg_by_userId = mean(rating), n = n()) %>%
  ggplot(aes(avg_by_userId)) + 
  geom_histogram(bins = 20, color = "black") + 
  ggtitle("Rating by the users") +
  xlab("rating")
```




### timestamp

Is the rating process affected by the time? timestamp can help us to find any relationship. First the histogram of the rating:

```{r , echo=FALSE}
edx %>%
  mutate(date = as.Date(as.POSIXct(timestamp, origin = "1970-01-01"))) %>%
  dplyr::count(date) %>% 
  ggplot(aes(n)) + 
  geom_histogram(bins = 30, color = "black") + 
  scale_x_log10() +
  ggtitle("Timestamp of the rate") +
  xlab("Timestamp of rate movies (log scale)")


```
Here we can not see to much dispersion of the data but it is not constant. Let get more detail.



Let's see the rating over time:

```{r, echo=FALSE}
edx %>%
  dplyr::count(timestamp) %>% 
  ggplot(aes(as.Date(as.POSIXct(timestamp, origin = "1970-01-01")))) + 
  geom_histogram(bins = 30) + 
  ggtitle("Timestamp of the rated movie") +
  xlab("Year") +
  ylab("count")
```
We see it is not constant. But all year the user are rating equal? This histogram shows they do not.

```{r, echo=FALSE}
edx %>%
  group_by(timestamp) %>% 
  summarise(avg_by_tm = mean(rating), n = n()) %>%
  ggplot(aes(avg_by_tm)) + 
  geom_histogram(bins = 10, color = "black") + 
  ggtitle("Rateing by Tiestamp of the movie") +
  xlab("Rating")
```
It is not to different from the prevoos rating graphs.


### genres

The genres in an arbitrary attribute that a move has. Actually can have more than one gender that in this dataset is separated in this column by pile line.


```{r}
n_distinct(edx$genres)
```
Then we have a lot of genres and they are not equally distributed!


```{r, echo=FALSE}
edx %>% group_by(genres) %>%
  summarise(n = n(), rat_gen = mean(rating)) %>%
  ggplot(aes(rat_gen)) + 
  geom_histogram(bins = 30, color = "black") + 
  ggtitle("Gender of the movie") +
  xlab("rating")
```

```{r, echo=FALSE}
head(edx) %>%
    select(title, genres)
```



We can create a new dataset that separate this genres, making the dataset bigger and taking care of 2 aspects:
1.- If we do in the training set we hve to do it in the validation set
2.- **Only** use for genres analysis, because we are going to change the dataset and any other analysis will be mislead

```{r, echo=FALSE}

edx_genres <- edx %>% 
   mutate(genres = fct_explicit_na(genres, na_level = "(no genres listed)")
          ) %>%
   separate_rows(genres, sep = "\\|")
head(edx_genres)
```
This process of separate the genres took a lot of memory: with less than 8 Gb in a linux system the R crash! 

```{r}
n_distinct(edx_genres$genre)
unique(edx_genres$genre)
```

Now we can repite the same question about the gender, now with this new classification of genres, can we see by genres thare are differences:

```{r, echo=FALSE}
edx_genres %>% group_by(genre) %>%
  summarise(n = n(), rat_gen = mean(rating)) %>%
  ggplot(aes(rat_gen)) + 
  geom_histogram(bins = 30, color = "black") + 
  ggtitle("Gender of the movie") +
  xlab("rating")
```

And we can see that different genres has different average rating:

```{r, echo=FALSE}
edx_genres %>% group_by(genre) %>%
  summarise(n = n(), rat_gen = mean(rating)) %>%
  ggplot(aes(x= genre, y=rat_gen)) + 
  geom_point() + 
  ggtitle("Rating by the Gender") +
  xlab("Genres") +
  ylab("rating") +
  theme(axis.text.x = element_text(angle = 60))   # Rotate axis labels
```


We just saw these data that came in the edx. Now the question is: How is it the rating affected by this predictors?
