# Methods and Analysis

*In this section we explain the process and techniques used, including data cleaning, data exploration and visualization, insights gained, and your modeling approach.*




# Loss function

The decision of better estimate will be based on the residual mean squared error (RMSE) on a test set. We define $y_{u,i}$ as the rating for movie $i$ by user $u$ and denote our prediction with $\hat{y}_{u,i}$. The RMSE is then defined as:

$$
\mbox{RMSE} = \sqrt{\frac{1}{N} \sum_{u,i}^{} \left( \hat{y}_{u,i} - y_{u,i} \right)^2 }
$$
with $N$ being the number of user/movie combinations and the sum occurring over all these combinations.


# Data exploration and visualization

## The dataset

The movielens 10M dataset had been split in edx and validation (90% and 10% respectively). Because we do not know nothing about validation (only we deduced from edx) we can see that edx has `r format(nrow(edx),big.mark=",")` rows but this only  `r format(n_distinct(edx$movieId),big.mark=",")` different movies and `r format(n_distinct(edx$userId),big.mark=",")` users. But if we create a matrix of the movies that we have in the dataset and the users we get a matrix of `r format(n_distinct(edx$movieId) * n_distinct(edx$userId), big.mark=",")` elements with a rating witch represent only the `r  format(100 * nrow(edx)/(n_distinct(edx$movieId) * n_distinct(edx$userId)), digits =2, nsmall =2)`% of the matrix. The rest is unknown: the user $u$ did not rate the movie $i$.
A matrix with mostly empty cells is called sparse, and the opposite to that (a mostly filled matrix) is called dense.

## Exploration
Each row in this dataset is and rating to the  movie i by the user u. But more info is stored and we will review initially if we can see some aspect we need to considered in the model.

Remember, we have these columns:

```{r edx columns, echo=FALSE}
names(edx)
```
The features/variables/columns in dataset are:

| Name       | Type     | Description     |
| :--------- | :------: | :-------------- |
|**movieId**|`r class(edx$movieId)`|  contains the unique identification number for each movie.
|**title**|`r class(edx$title)`|  contains the title of each movie and the year of release.
|**genres**|`r class(edx$genres)`| contains a list of pipe-separated of genre of each movie.
|**userId**|`r class(edx$userId)`| contains the unique identification number for each user.
|**rating**|`r class(edx$rating)`| contains the rating of one movie by one user. Ratings are made on a 5-Star scale with half-star increments.
|**timestamp**|`r class(edx$timestamp)`| contains the timestamp for one specific rating provided by one user.




### movieId

The movieId as its name make reference it s the Id of the movies in this dataset. Could be the title of the movie be enough? If that it is true, the number must be equal (a necessary condition is not a sufficient condition):

```{r Distinct movieId in edx}
n_distinct(edx$movieId)
```


```{r Distinct movie title in edx}
n_distinct(edx$title)

```
They are not. This is because some movies has the same title but not the same movieId...Why? 

```{r Show difference between number of movieId and distinct title, echo=FALSE, message=FALSE}

edx %>% group_by(movieId,title) %>% summarize(n()) %>% 
  group_by(title)%>%summarize(n = n(), movieId = movieId) %>% filter( n != 1)

```

Then we use the movieID for the analysis and the title it is not, except to show the results to make sense to our self.

One aspect to consider is that not all the movies has the same numbers of rating, e. gr., some movies has more vote than the others as we can see in the following histograms:

```{r Histograms of Movies rated, echo=FALSE}
edx %>% 
  dplyr::count(movieId) %>% 
  ggplot(aes(n)) + 
  geom_histogram(bins = 30, color = "black") + 
  scale_x_log10() + 
  ggtitle("Movies rated") +
  xlab("Number of rate per movie (log scale)")
```
You can see some movies has over a thousands of rating but one hundred of rating it is quite usual.

And obviously, not all the movies are rated equally:

```{r Histograms of Movies rating, echo=FALSE}
edx %>% 
  group_by(movieId) %>% 
  summarise(avg_by_movieId = mean(rating), n = n()) %>%
  ggplot(aes(avg_by_movieId)) + 
  geom_histogram(bins = 10, color = "black") + 
  #scale_x_log10() + 
  ggtitle("Movies rating") +
  xlab("Rating")
```
and here where our prediction system enter in play.


### rating

The rating is the value we want to predict but it is present in our dataset. This one allow us to training our system and it is called supervised learning algorithms in the AI.

```{r rating values,echo=FALSE}
unique(edx$rating) %>% data.frame() %>% arrange_all() %>% t() %>% as.numeric()
```

As we mention, the output it is a discrete, only 10 possible values.


### userId

This is the user who rate or vote. Not all the users rate the same amount of movies as we can see in the following histograms:

```{r Histograms of Users who rate, echo=FALSE}
edx %>%
  dplyr::count(userId) %>% 
  ggplot(aes(n)) + 
  geom_histogram(bins = 30, color = "black") + 
  scale_x_log10() +
  ggtitle("Users who rate") +
  xlab("Number of users who rate movies (log scale)")
```
Yo can see that are user that rate over a one thousand of movies!

Again, not all the user rate the movies in the same way.

```{r Histograms of Rating by the users, echo=FALSE}

edx %>%
  group_by(userId) %>% 
  summarise(avg_by_userId = mean(rating), n = n()) %>%
  ggplot(aes(avg_by_userId)) + 
  geom_histogram(bins = 20, color = "black") + 
  ggtitle("Rating by the users") +
  xlab("rating")
```




### timestamp

Is the rating process affected by the time? timestamp can help us to find any relationship. First the histogram of the rating:

```{r Histograms of Timestamp of the rate, echo=FALSE}
edx %>%
  mutate(date = as.Date(as.POSIXct(timestamp, origin = "1970-01-01"))) %>%
  dplyr::count(date) %>% 
  ggplot(aes(n)) + 
  geom_histogram(bins = 30, color = "black") + 
  scale_x_log10() +
  ggtitle("Timestamp of the rate") +
  xlab("Timestamp of rate movies (log scale)")


```
Here we can not see to much dispersion of the data but it is not constant. Let get more detail.



Let's see the rating over time:

```{r Histograms of Timestamp of the rated movie, echo=FALSE}
edx %>%
  dplyr::count(timestamp) %>% 
  ggplot(aes(as.Date(as.POSIXct(timestamp, origin = "1970-01-01")))) + 
  geom_histogram(bins = 30) + 
  ggtitle("Timestamp of the rated movie") +
  xlab("Year") +
  ylab("count")
```
We see it is not constant. But all year the user are rating equal? This histogram shows they do not.

```{r Histograms of Rating by Timestamp of the movie, echo=FALSE}
edx %>%
  group_by(timestamp) %>% 
  summarise(avg_by_tm = mean(rating), n = n()) %>%
  ggplot(aes(avg_by_tm)) + 
  geom_histogram(bins = 10, color = "black") + 
  ggtitle("Rating by Timestamp of the movie") +
  xlab("Rating")
```
It is not to different from the prevoos rating graphs.


### genres

The genres in an arbitrary attribute that a move has. Actually can have more than one gender that in this dataset is separated in this column by pile line.


```{r Distinct original genres}
n_distinct(edx$genres)
```
Then we have a lot of genres and they are not equally distributed!


```{r Histograms of Genres of the movie, echo=FALSE}
edx %>% group_by(genres) %>%
  summarise(n = n(), rat_gen = mean(rating)) %>%
  ggplot(aes(rat_gen)) + 
  geom_histogram(bins = 30, color = "black") + 
  ggtitle("Genres of the movie") +
  xlab("rating")
```

```{r edx genres, echo=FALSE}
head(edx) %>%
    select(title, genres)
```



We can create a new dataset that separate this genres, making the dataset bigger and taking care of 2 aspects:

1.- If we do in the training set we hve to do it in the validation set

2.- **Only** use for genres analysis, because we are going to change the dataset and any other analysis will be mislead

```{r Creating edx_genres}

# Creating a new dataset that contain one genre by row 
edx_genres <- edx %>% 
   mutate(genre = fct_explicit_na(genres, na_level = "(no genres listed)")
          ) %>%
   separate_rows(genre, sep = "\\|")
head(edx_genres)
```
This process of separate the genres took a lot of memory: with less than 8 Gb in a linux system the R version 3.6.3 crash!

The number of the new genre predictor:

```{r Number of the new genre predictor}
n_distinct(edx_genres$genre)
```


```{r New genre predictor}
unique(edx_genres$genre)
```

Now we can repeat the same question about the gender, now with this new classification of genres:

```{r Histograms of New Genre of the movie, echo=FALSE}
edx_genres %>% group_by(genre) %>%
  summarise(n = n(), rat_gen = mean(rating)) %>%
  ggplot(aes(rat_gen)) + 
  geom_histogram(bins = 30, color = "black") + 
  ggtitle("Genrer of the movie") +
  xlab("rating")
```

And we can see that different genres has different average rating:

```{r Plot of Rating by the Genre, echo=FALSE}
edx_genres %>% group_by(genre) %>%
  summarise(n = n(), rat_gen = mean(rating)) %>%
  ggplot(aes(x= genre, y=rat_gen)) + 
  geom_point() + 
  ggtitle("Rating by the Genre") +
  xlab("Genre") +
  ylab("rating") +
  theme(axis.text.x = element_text(angle = 60))   # Rotate axis labels
```


We just saw these data that came in the edx. Now the question is: How is it the rating affected by this predictors?

\newpage